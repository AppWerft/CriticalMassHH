<h1><em>speechrecognizer Module</em></h1>
<h2>Description</h2>
<p><em>speechrecognizer Module</em> allows you to use full features of Android SpeechRecognizer API.</p>
<p>You can </p>
<p>1) use three actions of Free Form, Web search and Hands free.</p>
<p>2) select the language from many languages which SpeechRecognizer service supports.</p>
<p>3) receive all events from SpeechRecognizer service (error, changeRms etc.)</p>
<p>4) check the supported features of Android device that SpeechRecognizer module is running on.</p>
<p>5) do safely everything because of SpeechRecognizer module handles the differrce of API Lavels (currently support API Level 8-16)</p>
<p>6) make your own custom UI design for SpeechRecognize.  <em>SpeechRecognizer module</em> uses direct mode of SpeechRecognizer API.</p>
<h2>Requrement</h2>
<p>Android min-sdk: Android 2.2 (API Level 8)
Titanium 2.1.0.GA</p>
<h2>Accessing the speechrecognizer Module</h2>
<p>To access this module from JavaScript, you would do the following:</p>
<pre><code>var speechrecognizerModule = require("jp.isisredirect.speechrecognizer");
</code></pre>
<p>The speechrecognizerModule variable is a reference to the Module object.  <br />
</p>
<p>To create speechrecognizer object from JavaScript, you would do the following:</p>
<pre><code>var speechrecognizer = speechrecognizerModule.createSpeechRecognizer();
</code></pre>
<p>The speechrecognizer variable is a reference to the SpeechRecognizer object.  <br />
</p>
<h2>Reference</h2>
<p>speechrecognizerModule object is coresponding to the static methods on SpeechRecognizer API.</p>
<p>On the other hand, SpeechRecognizer object is coresponding to the non static methods.</p>
<h3>module methods</h3>
<h4>speechrecognizerModule.isRecognitionAvailable()</h4>
<p>Whether Android device supports SpeechRecognizer.</p>
<h5>Parameters</h5>
<ul>
<li>void</li>
</ul>
<h5>Returns</h5>
<ul>
<li>Boolean</li>
</ul>
<p>true if Android device supports SpeechRecognizer.</p>
<h4>speechrecognizerModule.isVoiceSearchHandsFreeAvailable()</h4>
<p>Whether Android device supports Voice Search Hands Free feature.</p>
<h5>Parameters</h5>
<ul>
<li>void</li>
</ul>
<h5>Returns</h5>
<ul>
<li>Boolean</li>
</ul>
<p>true if Android device supports Voice Search Hands Free feature.</p>
<h4>speechrecognizerModule.getLanguageDetails()</h4>
<p>Requests the language informations supported by SpeechRecognizer.</p>
<p>This method's result is priovided by <em>languagedetails</em> event.</p>
<h5>Parameters</h5>
<ul>
<li>void</li>
</ul>
<h5>Returns</h5>
<ul>
<li>void</li>
</ul>
<p>More technical details is here:</p>
<p>http://developer.android.com/reference/android/speech/RecognizerIntent.html#ACTION_GET_LANGUAGE_DETAILS</p>
<h4>speechrecognizerModule.createSpeechRecognizer([Dictionary&lt;SpeechRecognizer&gt; parameters])</h4>
<p>create SpeechRecognizer object.</p>
<h5>Parameters</h5>
<ul>
<li>parameters: Dictionary&lt;SpeechRecognizer&gt;  (optional)</li>
</ul>
<p>Properties to set on a new object, including any defined by SpeechRecognizer</p>
<h5>Returns</h5>
<ul>
<li>SpeechRecognizer object</li>
</ul>
<h3>module events</h3>
<h4>languagedetails</h4>
<p>Fired when the results of speechrecognizerModule.getLanguageDetails() are ready after required by speechrecognizerModule.getLanguageDetails().</p>
<h5>Properties</h5>
<ul>
<li>source : Object</li>
</ul>
<p>Source object that fired the event.</p>
<ul>
<li>type : String</li>
</ul>
<p>Name of the event fired.</p>
<ul>
<li>language_preference : String</li>
</ul>
<p>represents the current language preference this user has specified - a locale string like "en-US".</p>
<ul>
<li>supported_languages : Array of Strings</li>
</ul>
<p>represents the languages supported by this implementation of voice recognition - a Array of strings like "en-US", "cmn-Hans-CN", etc.</p>
<h3>SpeechRecognizer properties</h3>
<h4>action:Number</h4>
<p>specifies the action of SpeechRecognizer.</p>
<p>there are three actions </p>
<p>1: Speech</p>
<p>2: Web search</p>
<p>3: Voice Search Hands Free</p>
<p>More technical details is here:</p>
<p><a href="http://developer.android.com/reference/android/speech/RecognizerIntent.html#ACTION_RECOGNIZE_SPEECH">http://developer.android.com/reference/android/speech/RecognizerIntent.html#ACTION_RECOGNIZE_SPEECH</a></p>
<p><a href="http://developer.android.com/reference/android/speech/RecognizerIntent.html#ACTION_WEB_SEARCH">http://developer.android.com/reference/android/speech/RecognizerIntent.html#ACTION_WEB_SEARCH</a></p>
<p><a href="http://developer.android.com/reference/android/speech/RecognizerIntent.html#ACTION_VOICE_SEARCH_HANDS_FREE">http://developer.android.com/reference/android/speech/RecognizerIntent.html#ACTION_VOICE_SEARCH_HANDS_FREE</a></p>
<h4>langtag : String</h4>
<p>informs the recognizer to perform speech recognition in a language.</p>
<p>You can use one of <em>supported_languanges</em> property of <em>languagedetails</em> event.</p>
<h5>default</h5>
<p>Android device setting</p>
<h4>langmodel : String</h4>
<p>Informs the recognizer which speech model to prefer when performing action.</p>
<p>available values are :</p>
<ul>
<li>
<p>"freeform"    (speechrecognizerModule.FREEFORM predefined)</p>
</li>
<li>
<p>"websearch"   (speechrecognizerModule.WEBSEARCH predefined)</p>
</li>
</ul>
<h5>default</h5>
<p>"freeform"</p>
<h4>maxresult : Number</h4>
<p>specifies limit on the maximum number of results to return when performing action.</p>
<h5>default</h5>
<p>1</p>
<h4>partialresult : Boolean</h4>
<p>indicate whether partial results should be returned by the recognizer as the user speaks.</p>
<h5>default</h5>
<p>false</p>
<h4>websearchonly : Boolean</h4>
<p>be used with action <em>web search</em>, to indicate whether to only fire web searches in response to a user's speech.</p>
<p>(note : this property may have no effect in this time. Because of direct mode recognition used in module, or the implementation of the recognizer service on current Android device.</p>
<h5>default</h5>
<p>false</p>
<h4>origin : String</h4>
<p>can be used with action <em>web search</em> to indicate the referer url of a page in which speech was requested.</p>
<p>(note : this property may have no effect in this time. Because of direct mode recognition used in module, or the implementation of the recognizer service on current Android device.</p>
<h5>default</h5>
<p>""</p>
<h4>secure : Boolean</h4>
<p>indicates that a "hands free" voice search was performed while the device was in a secure mode</p>
<h3>SpeechRecognizer methods</h3>
<h4>speechrecognizer.start()</h4>
<p>Starts listening for speech.</p>
<h5>Parameters</h5>
<ul>
<li>void</li>
</ul>
<h5>Returns</h5>
<ul>
<li>void</li>
</ul>
<h4>speechrecognizer.cancel()</h4>
<p>Cancels the speech recognition.</p>
<h5>Parameters</h5>
<ul>
<li>void</li>
</ul>
<h5>Returns</h5>
<ul>
<li>void</li>
</ul>
<h4>speechrecognizer.stop()</h4>
<p>Stops listening for speech.</p>
<h5>Parameters</h5>
<ul>
<li>void</li>
</ul>
<h5>Returns</h5>
<ul>
<li>void</li>
</ul>
<h4>speechrecognizer.release()</h4>
<p>release recognizer resources.</p>
<h5>Parameters</h5>
<ul>
<li>void</li>
</ul>
<h5>Returns</h5>
<ul>
<li>void</li>
</ul>
<h4>getErrorMessageFromErrorCode(int error):String</h4>
<p>gets error message from error code which is provided in <em>error</em> event.</p>
<h5>Parameters</h5>
<ul>
<li>error:Number</li>
</ul>
<p>error code received in error event.</p>
<h5>Returns</h5>
<ul>
<li>String</li>
</ul>
<p>error string that is correcponding to error code.</p>
<h3>SpeechRecognizer events</h3>
<h4>readyforspeech</h4>
<h5>Properties</h5>
<ul>
<li>source : Object</li>
</ul>
<p>Source object that fired the event.</p>
<ul>
<li>type : String</li>
</ul>
<p>Name of the event fired.</p>
<h4>beginningofspeech</h4>
<p>The user has started to speak.</p>
<h5>Properties</h5>
<ul>
<li>source : Object</li>
</ul>
<p>Source object that fired the event.</p>
<ul>
<li>type : String</li>
</ul>
<p>Name of the event fired.</p>
<h4>bufferreceived</h4>
<p>More sound has been received. </p>
<p>The purpose of this function is to allow giving feedback to the user regarding the captured audio. </p>
<p>There is no guarantee that this method will be called (depend on implementation of the recognizer service).</p>
<h5>Properties</h5>
<ul>
<li>source : Object</li>
</ul>
<p>Source object that fired the event.</p>
<ul>
<li>type : String</li>
</ul>
<p>Name of the event fired.</p>
<h4>rmschanged</h4>
<p>The sound level in the audio stream has changed. There is no guarantee that this method will be called.
There is no guarantee that this method will be called (depend on implementation of the recognizer service).</p>
<h5>Properties</h5>
<ul>
<li>source : Object</li>
</ul>
<p>Source object that fired the event.</p>
<ul>
<li>type : String</li>
</ul>
<p>Name of the event fired.</p>
<ul>
<li>rmsdb : float</li>
</ul>
<p>the new RMS dB value</p>
<h4>endofspeech</h4>
<p>Called after the user stops speaking.</p>
<h5>Properties</h5>
<ul>
<li>source : Object</li>
</ul>
<p>Source object that fired the event.</p>
<ul>
<li>type : String</li>
</ul>
<p>Name of the event fired.</p>
<h4>error</h4>
<p>A network or recognition error occurred.</p>
<h5>Properties</h5>
<ul>
<li>source : Object</li>
</ul>
<p>Source object that fired the event.</p>
<ul>
<li>type : String</li>
</ul>
<p>Name of the event fired.</p>
<ul>
<li>error: Number</li>
</ul>
<p>error code</p>
<h4>event</h4>
<p>Reserved for adding future events.</p>
<h5>Properties</h5>
<ul>
<li>source : Object</li>
</ul>
<p>Source object that fired the event.</p>
<ul>
<li>type : String</li>
</ul>
<p>Name of the event fired.</p>
<h4>partialresults</h4>
<p>Called when partial recognition results are available. </p>
<h5>Properties</h5>
<ul>
<li>source : Object</li>
</ul>
<p>Source object that fired the event.</p>
<ul>
<li>type : String</li>
</ul>
<p>Name of the event fired.</p>
<ul>
<li>results: Array of Strings</li>
</ul>
<p>the possible recognition results, where the first element is the most likely candidate.</p>
<ul>
<li>confidence_scores : Array of floats</li>
</ul>
<p>same size array as results, includes the confidence score of each result.</p>
<p>This value is optional and might not be provided.</p>
<p>The confidence score is ranging from 0.0 to 1.0, or -1 to represent an unavailable confidence score.</p>
<p>More technicall details :</p>
<p><a href="http://developer.android.com/reference/android/speech/SpeechRecognizer.html#CONFIDENCE_SCORES">http://developer.android.com/reference/android/speech/SpeechRecognizer.html#CONFIDENCE_SCORES</a></p>
<h4>results</h4>
<p>Called when recognition results are ready.</p>
<h5>Properties</h5>
<ul>
<li>source : Object</li>
</ul>
<p>Source object that fired the event.</p>
<ul>
<li>type : String</li>
</ul>
<p>Name of the event fired.</p>
<ul>
<li>results: Array of Strings</li>
</ul>
<p>the possible recognition results, where the first element is the most likely candidate.</p>
<ul>
<li>confidence_scores : Array of floats</li>
</ul>
<p>same size array as results, includes the confidence score of each result.</p>
<p>This value is optional and might not be provided.</p>
<p>The confidence score is ranging from 0.0 to 1.0, or -1 to represent an unavailable confidence score.</p>
<p>More technicall details :</p>
<p><a href="http://developer.android.com/reference/android/speech/SpeechRecognizer.html#CONFIDENCE_SCORES">http://developer.android.com/reference/android/speech/SpeechRecognizer.html#CONFIDENCE_SCORES</a></p>
<h2>Usage</h2>
<p>The most simply example of usage of SpeechRecoginither module is below:</p>
<pre><code>var speechrecognizerModule = require('jp.isisredirect.speechrecognizer');
Ti.API.info("module is =&gt; " + speechrecognizerModule);
var speechrecognizer = speechrecognizerModule.createSpeechRecognizer();
Ti.API.info("proxy is =&gt; " + speechrecognizer);
speechrecognizer.addEventListener(speechrecognizerModule.READYFORSPEECH, function(e) {
    // notify to user that Recognize is ready   
});
speechrecognizer.addEventListener(speechrecognizerModule.BEGINNINGOFSPEECH, function(e) {
    // notify to user that Recognizer detected user's voice
});
speechrecognizer.addEventListener(speechrecognizerModule.RESULTS, function(e) {
    // recognized results in e.results
});
speechrecognizer.start();
</code></pre>
<p>For more deep usage, you see /example/app.js</p>
<h2>Author</h2>
<p>Kastumi ISHIDA (isis re-direct) in k.i.office.</p>
<p>isis.redirect4@gmail.com</p>
<h2>License</h2>
<p>Copyright (c) 2013 Katsumi ISHIDA. All rights reserved.</p>
<p>Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:</p>
<p>The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.</p>
<p>THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.</p>